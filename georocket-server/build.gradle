plugins {
    id "de.undercouch.download" version "3.4.2"
}

apply plugin: 'java'
apply plugin: 'application'
apply plugin: 'maven'
apply plugin: 'checkstyle'
apply plugin: 'de.undercouch.download'

mainClassName = 'io.georocket.GeoRocket'

repositories {
    jcenter()
    exclusiveContent {
        forRepository {
            maven {
                url 'https://repo.osgeo.org/repository/release/'
            }
        }
        filter {
            includeGroup "jgridshift"
            includeGroup "org.geotools"
        }
    }
}

configurations.all {
    exclude group: 'org.slf4j', module: 'slf4j-log4j12'
}

dependencies {
    compile project(':georocket-common')
    compile project(':georocket-server-api')

    // include projects that announce themselves as extensions
    project.parent.allprojects.each {
        if (it.extensions.extraProperties.has('geoRocketServerExtension') &&
            it.extensions.extraProperties.get('geoRocketServerExtension')) {
            runtimeOnly it
        }
    }

    compile group: 'org.slf4j', name: 'jul-to-slf4j', version: '1.7.25'
    compile group: 'org.slf4j', name: 'log4j-over-slf4j', version: '1.7.25'
    compile group: 'org.slf4j', name: 'slf4j-api', version: '1.7.25'

    compile group: 'ch.qos.logback', name: 'logback-classic', version: '1.2.3'
    compile group: 'ch.qos.logback', name: 'logback-core', version: '1.2.3'

    compile "io.vertx:vertx-rx-java:$vertxVersion"
    compile "io.vertx:vertx-service-discovery:$vertxVersion"

    compile 'com.amazonaws:aws-java-sdk-s3:1.11.256'
    compile 'com.fasterxml:aalto-xml:1.0.0'
    compile 'com.h2database:h2:1.4.196'
    compile 'com.vividsolutions:jts:1.13'
    compile 'commons-io:commons-io:2.6'
    compile 'javax.servlet:javax.servlet-api:4.0.0'
    compile 'net.java.dev.jna:jna:4.5.1'
    compile 'org.apache.commons:commons-exec:1.3'
    compile 'org.apache.commons:commons-text:1.2'
    compile('org.apache.hadoop:hadoop-common:2.7.3') {
        // exclude netty because we want to use the version Vert.x depends on
        exclude group: 'io.netty'
        // exclude servlet-api v2, we add an explicit dependency to v3 instead
        exclude group: 'javax.servlet', module: 'servlet-api'
    }
    compile('org.apache.hadoop:hadoop-hdfs:2.7.3') {
        // exclude netty because we want to use the version Vert.x depends on
        exclude group: 'io.netty'
        // exclude servlet-api v2, we add an explicit dependency to v3 instead
        exclude group: 'javax.servlet', module: 'servlet-api'
    }
    compile 'org.jooq:jool:0.9.12'
    compile 'org.yaml:snakeyaml:1.19'

    // mongodb driver + snappy compression
    compile 'org.mongodb:bson:3.6.1'
    compile 'org.mongodb:mongodb-driver-async:3.6.1'
    compile 'org.xerial.snappy:snappy-java:1.1.4'

    // necessary for ALPN / HTTP/2
    runtime "io.netty:netty-tcnative-boringssl-static:2.0.7.Final"

    testCompile 'de.flapdoodle.embed:de.flapdoodle.embed.mongo:2.0.0'
    testCompile 'com.github.tomakehurst:wiremock-jre8:2.25.1'
    testCompile "io.vertx:vertx-unit:$vertxVersion"
    testCompile 'junit:junit:4.12'
    testCompile 'org.mongodb:mongodb-driver:3.6.1'
}

ext {
    elasticsearchUrl = new File(sourceSets.main.resources.srcDirs.first(),
        "elasticsearch_download_url.txt").text
    elasticsearchArchiveName = new File(new URL(elasticsearchUrl).path).name
    elasticsearchVersion = (elasticsearchUrl =~ /-([0-9]\.[0-9]\.[0-9])\.zip$/)[0][1]
    elasticsearchInstallDir = new File(projectDir, "elasticsearch/" + elasticsearchVersion)
}

// customize start scripts
startScripts {
    // customize application name
    applicationName = 'georocketd'

    // set GEOROCKET_HOME environment variable
    doLast {
        def windowsScriptFile = file(getWindowsScript())
        def unixScriptFile = file(getUnixScript())
        windowsScriptFile.text = windowsScriptFile.text
            .replaceFirst('set APP_HOME=.*', '$0\r\nset GEOROCKET_HOME=%APP_HOME%')
        unixScriptFile.text = unixScriptFile.text
            .replaceFirst('APP_HOME=.*', '$0\nexport GEOROCKET_HOME=\\$APP_HOME')
    }
}

distributions {
    main {
        contents {
            // include 'conf' directory in distribution
            from(projectDir) {
                include 'conf/**/*'
            }

            // include 'docs' in distribution
            from(tasks.getByPath(':docs:asciidoctor')) {
                into "docs"
                eachFile { f ->
                    f.path = f.path.replaceFirst(/html5\//, '')
                }
                includeEmptyDirs = false
            }

            // include Elasticsearch
            from(elasticsearchInstallDir.parent) {
                into 'elasticsearch'
            }
        }
    }
}

// do not upload ZIP and TAR distributions to Maven repo
configurations.archives.with {
    artifacts.removeAll { it.file =~ 'tar' }
    artifacts.removeAll { it.file =~ 'zip' }
}

/**
 * Download Elasticsearch to the build directory
 */
task downloadElasticsearch {
    doLast {
        // if the destination file does not exist yet, download Elasticsearch
        // to a temporary file and then rename it
        def destFile = new File(buildDir, elasticsearchArchiveName)
        if (!destFile.exists()) {
            def tempFile = new File(buildDir, "${elasticsearchArchiveName}.part")
            for (int i = 0; i < 5; ++i) {
                try {
                    download {
                        src elasticsearchUrl
                        dest tempFile
                        overwrite true
                    }
                    break
                } catch (Exception e) {
                    if (i == 4) {
                        throw e
                    }
                    logger.warn("Download failed. Retrying in 5 seconds ...")
                    Thread.sleep(5000)
                }
            }
            tempFile.renameTo(destFile)
        }
    }
}

/**
 * Extract Elasticsearch to the project directory
 */
task extractElasticsearch(dependsOn: downloadElasticsearch, type: Copy) {
    from zipTree(new File(buildDir, elasticsearchArchiveName))
    into elasticsearchInstallDir
    includeEmptyDirs = false // necessary to remove first path item
    eachFile { f ->
        // remove first path item
        f.path = f.path.replaceFirst(/.+?\//, '')
    }
} doLast {
    // make sure 'plugins' directory exists (necessary to start Elasticsearch)
    def pluginsDir = new File(elasticsearchInstallDir, 'plugins')
    pluginsDir.mkdirs()

    // make sure 'logs' directory exists
    def logsDir = new File(elasticsearchInstallDir, 'logs')
    logsDir.mkdirs()

    // Delete all x-pack plugins. We don't need them for the embedded version.
    def modulesDir = new File(elasticsearchInstallDir, 'modules')
    delete modulesDir.listFiles().findAll { it.getName().startsWith('x-pack') }
}

task cleanExtractedElasticsearch(type: Delete) {
    delete 'elasticsearch'
}

processResources.dependsOn(extractElasticsearch)
eclipseClasspath.dependsOn(extractElasticsearch)

clean.dependsOn(cleanExtractedElasticsearch)

// Fix command-length issue in windows startscript
// see https://issues.gradle.org/browse/GRADLE-2992
task pathingJar(type: Jar) {
    appendix = 'pathing'
    manifest { attributes("Class-Path": configurations.runtime.collect { it.getName() }.join(' ') + ' ' + jar.archiveName ) }
}
applicationDistribution.from(pathingJar) { into "lib" }
startScripts {
    doLast {
        def winScriptFile  = file getWindowsScript()
        def winFileText = winScriptFile.text

        // Remove too-long-classpath and use pathing jar instead
        winFileText = winFileText.replaceAll('set CLASSPATH=.*', 'rem CLASSPATH declaration removed.')
        winFileText = winFileText.replaceAll('("%JAVA_EXE%" .* -classpath ")%CLASSPATH%(" .*)', '$1%APP_HOME%\\\\lib\\\\' + pathingJar.archiveName + '$2')

        winScriptFile.text = winFileText
    }
}
