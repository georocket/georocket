georocket:
  # The host GeoRocket should bind to
  host: 127.0.0.1

  # The TCP port GeoRocket should listen on
  port: 63020

  # Configuration for the HTTP interface
  http:
    compress: true
    ssl: false
    certPath: georocket.crt
    keyPath: georocket.key
    alpn: false

    # Cross-Origin Resource Sharing (CORS)
    cors:
      enable: false
      allowOrigin: https?://localhost(:[0-9]+)?

  # Log configuration at startup (useful for debugging)
  logConfig: false

  # Logging
  logs:
    enabled: true
    level: INFO
    logFile: logs/georocket.log
    dailyRollover:
      enabled: true
      maxDays: 7
      maxSize: 104857600

  # Back-end configuration
  storage:
    # The data store implementation to use
    # driver: file
    # driver: h2
    driver: mongodb
    # driver: postgresql
    # driver: s3

    # Configuration for the file back-end
    file:
      path: $GEOROCKET_HOME/storage

    # Configuration for the H2 database back-end
    h2:
      path: $GEOROCKET_HOME/storage/georocket
      compress: false

    # Configuration for the MongoDB back-end
    # mongodb:
    #   connectionString: mongodb://localhost:27017/georocket?compressors=snappy

    # postgresql:
    #   url: jdbc:postgresql://localhost:5432/georocket?currentSchema=georocket
    #   username: georocket
    #   password: georocket

    # Configuration for the S3 back-end
    s3:
      accessKey: myAccessKey
      secretKey: mySecretKey
      host: localhost
      port: 12345
      bucket: georocket
      pathStyleAccess: true
      forceSignatureV2: false
      requestExpirySeconds: 600

  # Index configuration
  index:
    driver: mongodb
    # driver: postgresql

    # The maximum number of chunks to insert in one bulk
    maxBulkSize: 200

    # The maximum number of bulk processes to run in parallel. Also affects the
    # number of parallel bulk inserts into Elasticsearch.
    maxParallelInserts: 5

    # The maximum number of chunks the indexer queues due to backpressure before
    # it pauses the import. If this happens, the indexer will later unpause the
    # import as soon as at least half of the queued chunks have been indexed.
    maxQueuedChunks: 10000

    # Properties and/or attributes, for which to add database indexes in addition to the generic database indexes that
    # are always created. This allows efficient range queries for the listed fields with the postgres driver.
    #
    # For example, the query 'LTE(scalerank 2)' would benefit from declaring 'scalerank' as an indexed field.
    # It is not necessary to include fields that are only ever used with equality conditions. For example, a field
    # such as 'country_code' would only make sense to be used like 'EQ(country_code de)' but not  as a
    # range query (LT, LTE, GT, GTE operators).
    # Also, the mongodb driver currently does not use the indexed fields, so indexedFields can be left empty
    # when using mongodb.
    indexedFields:
      - scalerank

    # After chunks have been imported into the store and before they are
    # indexed, they are temporarily put into a cache to save bandwidth and time.
    indexableChunkCache:
      # The cache's maximum size in bytes (the default value equals 64 MB)
      maxSize: 67108864
      # The maximum number of seconds a chunk stays in the cache
      maxTimeSeconds: 60

    mongodb:
      connectionString: mongodb://localhost:27017/georocket?compressors=snappy

    postgresql:
      url: jdbc:postgresql://localhost:5432/georocket?currentSchema=georocket
      username: georocket
      password: georocket

  tasks:
    # the maximum number of seconds information about a task should be kept
    # and provided through the tasks endpoint after the task has finished
    retainSeconds: 120

  embeddedMongoDB:
    storagePath: $GEOROCKET_HOME/storage/mongodb
